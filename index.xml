<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ops</title>
    <link>https://ops.m114.org/</link>
    <description>Recent content on ops</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>&amp;copy; 2014-2021. All rights reserved.</copyright>
    <lastBuildDate>Fri, 08 Oct 2021 11:13:08 +0800</lastBuildDate><atom:link href="https://ops.m114.org/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>使用OpenResty reload ipsec服务</title>
      <link>https://ops.m114.org/post/openresty-privileged-agent/</link>
      <pubDate>Fri, 08 Oct 2021 11:13:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/openresty-privileged-agent/</guid>
      <description>背景介绍  Debian 11 OpenResty 1.19.9.1  默认情况下，Nginx/OpenResty会启动一个root权限运行的master进程，之后再用指定的普通用户权限启动对应的worker，因要root权限才能操作ipsec服务，为了解决普通worker的提权问题，OpenResty提供了一个privileged agent来对这些提权操作进行处理，本文就是利用privileged agent来实现ipsec服务的重启操作。
基本思路 在OpenResty的 init_by_lua_block 阶段启动privileged agent，之后在 init_worker_by_lua_block 阶段针对privileged agent设置其具体需要执行的操作，最终在 content_by_lua_block 中通过改变共享内存的 lua_shared_dict 字段的内容触发对应的reload操作。
对应配置 root@debian:~# cat /etc/openresty/nginx.conf ... user app; #普通用户启动worker ... http { ... lua_shared_dict reload_status 1m; #共享内存dict init_by_lua_block { local process = require &amp;#34;ngx.process&amp;#34; -- enables privileged agent process local ok, err = process.enable_privileged_agent() if not ok then ngx.log(ngx.ERR, &amp;#34;enables privileged agent failed error:&amp;#34;, err) end -- output process type ngx.</description>
    </item>
    
    <item>
      <title>使用OpenResty mTLS认证</title>
      <link>https://ops.m114.org/post/openresty-mtls/</link>
      <pubDate>Wed, 29 Sep 2021 13:08:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/openresty-mtls/</guid>
      <description>环境  CentOS 7 OpenResty 1.19.9.1  cosocket-mtls patch  ngx_lua-0.10.20_01-cosocket-mtls.patch lua-resty-core-0.1.22_01-cosocket-mtls.patch   lua-resty-http    为了支持mTLS功能，折腾的够呛，OpenResty官方又没支持，基于OpenResty的APISIX和Kong都有补丁，但两家公司的补丁又有点细微的差别。APISIX的定制OpenResty版本目前仅支持到1.19.3，而Kong的定制OpenResty跟官方版本是同步的。此处的方案就是用Kong的patch和APISIX的lua-resty-http(我稍微改了一丢丢兼容Kong的patch)。
功能  OpenResty作为客户端调用外部HTTP接口, 使用mTLS认证  Server配置 对应nginx配置
server { listen 443 ssl; server_name ssl.test.com; ssl_certificate ssl/mtls_server.crt; #server公钥 ssl_certificate_key ssl/mtls_server.key; #server私钥 ssl_client_certificate ssl/mtls_ca.crt; #根级证书公钥，用于验证各个二级client ssl_verify_client on; } 请求验证  curl命令行验证  curl --resolve ssl.test.com:443:127.0.0.1 --cacert ssl/mtls_ca.crt --cert ssl/mtls_client.crt --key mtls_client.key https://ssl.test.com  lua-resty-http验证  location /t { resolver local=on ipv6=off; resolver_timeout 5s; lua_ssl_verify_depth 1; lua_ssl_trusted_certificate /data/nginx/mtls/ca.</description>
    </item>
    
    <item>
      <title>CFSSL使用</title>
      <link>https://ops.m114.org/post/cfssl/</link>
      <pubDate>Tue, 28 Sep 2021 09:08:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/cfssl/</guid>
      <description>简介 1. cfssl安装 2. cfssl常用命令 3. 创建CA证书  3.1 CA证书配置 3.2 CA CSR请求 3.3 生成CA证书和私钥 3.4 其他   4. 签发Server证书 5. 签发Client证书 6. 签发peer证书 7. 校验证书  简介 在工作中，我们经常会遇到各种证书问题，如k8s,etcd等服务时，我们往往都要使用证书，本文将使用CFSSL工具快速简单的配置证书。这里将生成三种证书包含客户端证书、服务端证书、双向证书。
 client certificate: 用于服务端认证客户端，例如etcdctl、etcd proxy、fleetctl、docker客户端 server certificate: 服务端使用，客户端以此验证服务端身份，例如docker服务端、kube-apiserver peer certificate: 双向证书，用于etcd集群成员间通信  1. cfssl安装 项目地址: https://github.com/cloudflare/cfssl
wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssl_1.6.1_linux_amd64 -O /usr/local/bin/cfssl wget https://github.com/cloudflare/cfssl/releases/download/v1.6.1/cfssljson_1.6.1_linux_amd64 -O /usr/local/bin/cfssljson chmod +x /usr/local/bin/{cfssl,cfssljson} 2. cfssl常用命令 # 初始化CA cfssl gencert -initca ca-csr.json | cfssljson -bare ca # 查看cert(证书信息) cfssl certinfo -cert ca.</description>
    </item>
    
    <item>
      <title>使用OpenResty实现简易CC防护</title>
      <link>https://ops.m114.org/post/openresty-anticc/</link>
      <pubDate>Sat, 11 Sep 2021 11:08:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/openresty-anticc/</guid>
      <description>环境  CentOS 7 OpenResty 1.19.9.1  lua-resty-ipmatcher lua-var-nginx-module    功能  支持IP白名单 支持IP黑名单 计数key为：ip + &amp;ldquo;.&amp;rdquo; + md5(host + request_uri + useragent)，可自定义 60秒内请求超过60次就封禁3600秒  配置 对应nginx配置
lua_shared_dict cc_counter 100m; server { listen 80; server_name demo.test.com; location / { access_by_lua_file lua/anticc.lua; } } anticc.lua
 </description>
    </item>
    
    <item>
      <title>防止SNI信息泄露</title>
      <link>https://ops.m114.org/post/use-ssl_reject_handshake/</link>
      <pubDate>Sun, 04 Jul 2021 10:08:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/use-ssl_reject_handshake/</guid>
      <description>有了 ssl_reject_handshake (Nginx ≥ 1.19.4)这个参数，再也不需要strict-sni.patch了。
本质需求就是为了当机器人或者奇怪的人类通过HTTPS访问你的IP时不暴露证书，也就不会暴露域名。
官方文档给了个例子如下，在以下配置中，除example.com以外，其他域名的SSL握手将被拒绝。（返回UNRECOGNIZED NAME，Chrome提示ERR_SSL_UNRECOGNIZED_NAME_ALERT）
server { listen 443 ssl default_server; ssl_reject_handshake on; } server { listen 443 ssl; server_name example.com; ssl_certificate example.com.crt; ssl_certificate_key example.com.key; } 注意事项
 nginx无法启用tls1.3的握手失败解决办法，openssl 1.1.1h bug，详细见传送门。  升级至openssl ≥ 1.1.1j 修复此问题    </description>
    </item>
    
    <item>
      <title>巧用 cache-control: s-maxage 优化CDN和浏览器缓存同步</title>
      <link>https://ops.m114.org/post/use-s-maxage-for-cdn/</link>
      <pubDate>Mon, 14 Jun 2021 11:18:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/use-s-maxage-for-cdn/</guid>
      <description>在实际使用中会发现，通常源站资源发生变化后，我们会尝试刷新CDN。但是由于用户浏览器依旧保留旧资源，造成访问不一致的问题。解决思路如下:
在源站添加如下header:
 cache-control: max-age=0,s-maxage=604800
 解释说明
CDN 通常会遵循这个头，如果仅仅设置cache-control: max-age=0，固然每次浏览器会向 CDN 请求验证资源新鲜度，但是也会造成 CDN 每次都回源验证，会引起缓存击穿的问题。而静态资源通常更新并不频繁，我们可能会期望浏览器仅仅找 CDN 验证新鲜度就够了，CDN 不需要回源。对于这种场景，在cache-control头中添加s-maxage参数就够了。这个参数 CDN 通常会处理，优先级比max-age高。这样就实现了我们的需求。
Ps: 最理想的方案仍然是cache busting。此方案仅适用于实在无法做到的静态资源。对于一些不需要太重视新鲜度问题的资源，仅仅max-age参数就够了，这样可能尽可能在浏览器段缓存资源，减少 CDN 的请求流量。
CDN厂商 s-maxage 支持情况
 阿里云CDN【支持】 腾讯云CDN【不支持】 华为云CDN【不支持】 Akamai CDN【支持】 Google cloud CDN【支持】 AWS cloudfront CDN【支持】  Cache-Control 示例说明  Cache-Control: public max-age=3600 //本地缓存和 CDN 缓存均缓存 1 小时； Cache-Control: private immutable //不能缓存在 CDN，只能缓存在本地。并且一旦被缓存了，则不能被更新； Cache-Control: no-cache //不能缓存。如果一定要缓存的话，确保对其进行了二次验证； Cache-Control: public max-age=3600 s-maxage=7200 //本地缓存 1 小时，CDN 上缓存 2 小时； Cache-Control: public max-age=3600 proxy-revalidate //本地和 CDN 均缓存 1 小时。但是如果 CDN 收到请求，则尽管已经缓存了 1 小时，还是要检查源中文档是否已经被改变。  参考  https://blog.</description>
    </item>
    
    <item>
      <title>使用Nginx实现授权下载</title>
      <link>https://ops.m114.org/post/nginx-authorized-download/</link>
      <pubDate>Fri, 11 Jun 2021 11:18:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/nginx-authorized-download/</guid>
      <description>使用Nginx实现授权下载有两种方式，一种是nginx自带 --with-http_secure_link_module，另外一种是lua自定义实现。
方法一 1.1 安装
编译时添加此参数 --with-http_secure_link_module
1.2 配置
server { listen 80; server_name download.test.com; root /data/wwwroot; access_log logs/download.access.log main; location / { secure_link $arg_st,$arg_e; secure_link_md5 FIJaVSEV23$uri$arg_e; if ($secure_link = &amp;#34;&amp;#34;) { return 403; } if ($secure_link = &amp;#34;0&amp;#34;) { return 410; } } } 1.3 使用
# shell脚本示例如下 secret=&amp;#34;FIJaVSEV23&amp;#34; # 见前面secure_link_md5配置 uri=&amp;#34;/待下载文件路径&amp;#34; datetime=$(date -d&amp;#39;1day&amp;#39; +&amp;#39;%Y-%m-%d %H:%M:%S&amp;#39;) etime=$(date +%s -d&amp;#34;${datetime}&amp;#34;) token=$(echo -n &amp;#34;${secret}${uri}${etime}&amp;#34; | openssl md5 -binary | openssl base64 | tr +/ -_ | tr -d =) # 下载链接 dlurl=&amp;#34;dowload.</description>
    </item>
    
    <item>
      <title>lua实现微信机器人</title>
      <link>https://ops.m114.org/post/nginx-wechat-ops/</link>
      <pubDate>Fri, 11 Jun 2021 10:08:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/nginx-wechat-ops/</guid>
      <description>使用企业微信调整值班人员信息，示例为联系人tag调整，可以自定义任何想实现功能。
环境  CentOS 7 Nginx  lua-nginx-module lua-resty-http lua实现微信加密库 xml2lua ≤ v1.4-5   依赖服务  企业微信    配置 对应nginx配置
server { listen 443 ssl http2; ssl_certificate test.crt; ssl_certificate_key test.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; ssl_ciphers EECDH+CHACHA20:EECDH+CHACHA20-draft:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; ssl_session_timeout 1d; ssl_session_cache shared:SSL:20m; add_header Strict-Transport-Security max-age=31536000; server_name wx-ops.test.com; access_log logs/wechat-ops.access.log main; error_log logs/wechat-ops.info; location /api/ { resolver local=on ipv6=off; resolver_timeout 2s; lua_ssl_verify_depth 1; lua_ssl_trusted_certificate /etc/pki/tls/certs/ca-bundle.crt; content_by_lua_file lua/wechat-ops.lua; } } wechat_ops.</description>
    </item>
    
    <item>
      <title>MySQL插件之审计</title>
      <link>https://ops.m114.org/post/MySQL-plugin-Audit/</link>
      <pubDate>Tue, 08 Jun 2021 14:10:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/MySQL-plugin-Audit/</guid>
      <description>目录  等保需求 背景 插件安装 插件配置  等保需求  审计功能：记录时间、来源IP、用户、行为、数据库、SQL。  背景 Oracle 的 MySQL 社区版不带审计插件（Audit Plugin），要想使用审计功能，你可以用企业版，不过这需要银子。业界还有一些 GPL 协议的审计插件，这里我们选择 MariaDB 的审计插件。
 系统版本: CentOS 7.4 MySQL版本: 5.7.23 社区版 MariaDB审计插件版本: 1.4.7  备注:
 MariaDB审计插件一直在更新，不同版本的审计插件功能也不同，每个版本的功能见：https://mariadb.com/kb/en/mariadb-audit-plugin-options-and-system-variables/#server_audit_events 我们在给MySQL数据库安装审计插件时，需要从MariaDB里面拷贝审计插件。MariaDB版本与审计插件版本关系如下：https://mariadb.com/kb/en/mariadb-audit-plugin-versions/  插件安装 MariaDB 的 10.1 版本对应与 Oracle 的 MySQL 5.7，我们到它的官网上下载 Linux 的通用版本。
找到我们需要的审计插件：
./mariadb-10.1.48-linux-x86_64/lib/plugin/server_audit.so 把这个 so 结尾的文件拷贝到 MySQL 的插件目录，例如：/usr/local/mysql/lib/plugin/
-- 配置文件增加以下配置 [mysqld] plugin_load_add = server_audit server_audit = FORCE_PLUS_PERMANENT # 防止审计插件被卸载 server_audit_logging = on server_audit_events = CONNECT,TABLE,QUERY_DDL,QUERY_DCL,QUERY_DML_NO_SELECT server_audit_file_rotate_size = 268435456 server_audit_file_rotations = 64 -- 插件动态安装启用 mysql&amp;gt; install plugin server_audit SONAME &amp;#39;server_audit.</description>
    </item>
    
    <item>
      <title>MySQL插件之密码复杂性</title>
      <link>https://ops.m114.org/post/MySQL-plugin-validate-password/</link>
      <pubDate>Tue, 08 Jun 2021 13:30:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/MySQL-plugin-validate-password/</guid>
      <description>目录  等保需求 插件介绍 插件安装 插件配置  等保需求  用户密码复杂度：3种字符以上，至少8位长度。使用 validate_password 插件实现。  插件介绍 MySQL 5.6/5.7 上密码复杂度策略实现, MySQL 8.0有组件实现方式，同时也支持插件方式。
插件安装 -- 配置文件增加以下配置 [mysqld] plugin-load-add = validate_password.so validate-password = FORCE_PLUS_PERMANENT -- 插件动态安装启用 mysql&amp;gt; INSTALL PLUGIN validate_password soname &amp;#39;validate_password.so&amp;#39;; -- 验证是否正常安装 mysql&amp;gt; SELECT PLUGIN_NAME, PLUGIN_LIBRARY, PLUGIN_STATUS, LOAD_OPTION FROM INFORMATION_SCHEMA.PLUGINS WHERE PLUGIN_NAME = &amp;#39;validate_password&amp;#39;; mysql&amp;gt; SHOW PLUGINS; 注意：参数FORCE_PLUS_PERMANENT是为了防止插件在MySQL运行的时候被卸载，如下所示，当你卸载插件时就会报错： mysql&amp;gt; UNINSTALL PLUGIN validate_password; ERROR 1702 (HY000): Plugin &amp;#39;validate_password&amp;#39; is force_plus_permanent and can not be unloaded 插件配置 -- 查看默认相关变量 mysql&amp;gt; show variables like &amp;#39;validate_password%&amp;#39;; +--------------------------------------+--------+ | Variable_name | Value | +--------------------------------------+--------+ | validate_password_check_user_name | OFF | | validate_password_dictionary_file | | | validate_password_length | 8 | | validate_password_mixed_case_count | 1 | | validate_password_number_count | 1 | | validate_password_policy | MEDIUM | | validate_password_special_char_count | 1 | +--------------------------------------+--------+ mysql&amp;gt; select password(&amp;#39;abc&amp;#39;); ERROR 1819 (HY000): Your password does not satisfy the current policy requirements mysql&amp;gt; select password(&amp;#39;abc123&amp;#39;); ERROR 1819 (HY000): Your password does not satisfy the current policy requirements mysql&amp;gt; select password(&amp;#39;abc123ABC&amp;#39;); ERROR 1819 (HY000): Your password does not satisfy the current policy requirements mysql&amp;gt; select password(&amp;#39;abc123@A&amp;#39;); 所以你更改密码必须满足：数字、小写字母、大写字母 、特殊字符、长度至少8位 参数说明:</description>
    </item>
    
    <item>
      <title>MySQL插件之Connection-Control</title>
      <link>https://ops.m114.org/post/MySQL-plugin-Connection-Control/</link>
      <pubDate>Tue, 08 Jun 2021 13:10:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/MySQL-plugin-Connection-Control/</guid>
      <description>目录  等保需求 插件介绍 插件安装 插件配置  等保需求  登录失败策略：登录失败5次锁定10分钟，使用 Connection-Control 插件实现。  插件介绍 MySQL 5.7.17 以后提供了 Connection-Control 插件用来控制客户端在登录操作连续失败一定次数后的响应的延迟。该插件可有效的防止客户端暴力登录的风险(攻击)。该插件包含以下2个组件:
 CONNECTION_CONTROL：用来控制登录失败的次数及延迟响应时间 CONNECTION_CONTROL_FAILED_LOGIN_ATTEMPTS：该表将登录失败的操作记录至IS库中  插件安装 -- 配置文件增加以下配置 [mysqld] plugin-load-add	= connection_control.so connection-control = FORCE_PLUS_PERMANENT // 防止运行时卸载 connection-control-failed-login-attempts = FORCE_PLUS_PERMANENT // 防止运行时卸载 connection_control_min_connection_delay	= 600000 connection_control_max_connection_delay	= 2147483647 connection_control_failed_connections_threshold	= 5 -- 插件动态安装启用 mysql&amp;gt; INSTALL PLUGIN CONNECTION_CONTROL SONAME &amp;#39;connection_control.so&amp;#39;; mysql&amp;gt; INSTALL PLUGIN CONNECTION_CONTROL_FAILED_LOGIN_ATTEMPTS SONAME &amp;#39;connection_control.so&amp;#39;; -- 验证是否正常安装 mysql&amp;gt; SELECT PLUGIN_NAME, PLUGIN_STATUS FROM INFORMATION_SCHEMA.</description>
    </item>
    
    <item>
      <title>sysbench试用</title>
      <link>https://ops.m114.org/post/sysbench-trial/</link>
      <pubDate>Tue, 08 Jun 2021 10:10:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/sysbench-trial/</guid>
      <description>目录  背景 环境 安装 测试  背景 主要测试开启审计插件OLTP性能损失多大，安装和测试方法如下
环境  CentOS 7.4 MySQL: 5.7.23  innodb_buffer_pool_size: 8G innodb_buffer_pool_instances: 8【默认】 innodb_buffer_pool_chunk_size: 134217728【即128M，默认值】    安装 yum install gcc gcc-c++ autoconf automake make libtool bzr mysql-devel mysql wget https://github.com/akopytov/sysbench/archive/refs/tags/1.0.20.tar.gz tar zxf 1.0.20.tar.gz cd sysbench-1.0.20 ./autogen.sh ./configure --prefix=/usr/local/sysbench make make install 测试  创建测试库  mysql&amp;gt; create database sbtest;  测试只读性能，整个过程将持续10分钟  #准备数据 sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --table_size=25000 --tables=250 --events=0 --time=600 oltp_read_only prepare #运行workload sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --table_size=25000 --tables=250 --events=0 --time=600 --threads=XXX --percentile=95 --range_selects=0 --skip-trx=1 --report-interval=1 oltp_read_only run #清理 sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --table_size=25000 --tables=250 --events=0 --time=600 --threads=XXX --percentile=95 --range_selects=0 oltp_read_only cleanup  测试写入性能，整个过程将持续10分钟  #准备数据 sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --table_size=25000 --tables=250 --events=0 --time=600 oltp_write_only prepare #运行workload sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --mysql-ignore-errors=1062 --table_size=25000 --tables=250 --events=0 --time=600 --threads=XXX --percentile=95 --report-interval=1 oltp_write_only run #清理 sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --table_size=25000 --tables=250 --events=0 --time=600 --threads=XXX --percentile=95 oltp_write_only cleanup  测试混合读写性能，整个过程将持续10分钟  #准备数据 sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --table_size=25000 --tables=250 --events=0 --time=600 oltp_read_write prepare #运行workload sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --mysql-ignore-errors=1062 --table_size=25000 --tables=250 --events=0 --time=600 --threads=XXX --percentile=95 --report-interval=1 oltp_read_write run #清理 sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --table_size=25000 --tables=250 --events=0 --time=600 --threads=XXX --percentile=95 oltp_read_write cleanup FAQ Q: 128线程只读测试时，报错如下:</description>
    </item>
    
    <item>
      <title>python 3.9.5 编译报错 Could not import runpy module 问题</title>
      <link>https://ops.m114.org/post/python-3.9.5-build-error/</link>
      <pubDate>Sat, 05 Jun 2021 13:15:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/python-3.9.5-build-error/</guid>
      <description>环境  CentOS 7.3.1611 gcc-4.8.5-28.el7_5.1 Python 3.9.5  相关报错 ./python -E -S -m sysconfig --generate-posix-vars ;\ if test $? -ne 0 ; then \ 	echo &amp;#34;generate-posix-vars failed&amp;#34; ; \ 	rm -f ./pybuilddir.txt ; \ 	exit 1 ; \ fi Could not import runpy module Traceback (most recent call last): File &amp;#34;/tmp/Python-3.9.5/Lib/runpy.py&amp;#34;, line 15, in &amp;lt;module&amp;gt; import importlib.util File &amp;#34;/tmp/Python-3.9.5/Lib/importlib/util.py&amp;#34;, line 2, in &amp;lt;module&amp;gt; from . import abc File &amp;#34;/tmp/Python-3.</description>
    </item>
    
    <item>
      <title>lua发布消息至RocketMQ解耦</title>
      <link>https://ops.m114.org/post/nginx-use-mq/</link>
      <pubDate>Thu, 03 Jun 2021 15:08:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/nginx-use-mq/</guid>
      <description>广告点击回传数据入消息队列，避免后端处理不过来，先存入消息队列削峰。
环境  CentOS 7 Nginx  lua-nginx-module lua-resty-core lua-resty-http   依赖服务  阿里云RocketMQ    配置 对应nginx location配置
location / { access_by_lua_file lua/mq/mq.lua; } custom/mq.lua
return { AKId = &amp;#34;xxx&amp;#34;, -- RocketMQ的AccessKeyId AKSecret = &amp;#34;xxx&amp;#34;, -- RocketMQ的AccessKeySecret topic_name = &amp;#34;xxx&amp;#34;, -- RocketMQ的topic instance_id = &amp;#34;xxx&amp;#34; -- RocketMQ的instance_id } mq.lua
local require = require local ngx = ngx local config = require(&amp;#34;custom.mq.config&amp;#34;) local http = require &amp;#34;resty.http&amp;#34; local cjson = require &amp;#34;cjson.</description>
    </item>
    
    <item>
      <title>使用动态 DNS 来完成 HTTP 请求</title>
      <link>https://ops.m114.org/post/dynamic-http-proxy/</link>
      <pubDate>Thu, 03 Jun 2021 14:38:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/dynamic-http-proxy/</guid>
      <description>内部访问外部http请求，通过拦截内部请求至此统一访问外部业务。
环境  CentOS 7 Nginx  lua-nginx-module lua-resty-dns lua-resty-lock lua-resty-http    配置 对应nginx配置
lua_shared_dict dns_cache 5m; lua_shared_dict my_locks 1m; server { listen 80; server_name *.test.com; access_log logs/dyn_http.access.log default; location / { content_by_lua_file &amp;#39;lua/dyn_http.lua&amp;#39;; } } dyn_http.lua
local require = require local ngx = ngx local resolver = require &amp;#34;resty.dns.resolver&amp;#34; local resty_lock = require &amp;#34;resty.lock&amp;#34; local http = require &amp;#34;resty.http&amp;#34; local cache = ngx.shared.dns_cache local function fail(msg, err) ngx.</description>
    </item>
    
    <item>
      <title>Nginx实现ip查询服务</title>
      <link>https://ops.m114.org/post/nginx-ipip-service/</link>
      <pubDate>Thu, 03 Jun 2021 13:08:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/nginx-ipip-service/</guid>
      <description>实现内部IP查询服务
 查询当前公网IP 查询当前公网IP地理信息，支持IPv4/IPv6 查询指定IP的地理信息，支持IPv4/IPv6  环境  CentOS 7 Nginx  lua-nginx-module lua-resty-ipmatcher lua-resty-ip2region lua-resty-maxminddb   IP库  ip2region ipv4库 maxminddb 免费ipv6库    配置 lua_shared_dict ip_data 10m; server { server_name ip.test.com; access_log logs/ip.access.log main buffer=32k flush=10s; error_log logs/ip.error.log; location / { default_type &amp;#39;text/plain&amp;#39;; access_by_lua_block { local remote_addr = ngx.var.remote_addr ngx.print(remote_addr) } } location = /ip { default_type application/json; content_by_lua_block { local require = require local ngx = ngx local cjson = require &amp;#34;cjson.</description>
    </item>
    
    <item>
      <title>Gogs/Gitea webhook支持</title>
      <link>https://ops.m114.org/post/gitea-webhook/</link>
      <pubDate>Thu, 03 Jun 2021 10:08:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/gitea-webhook/</guid>
      <description>实现需求为git提交后，自动同步至webhook所在机器的指定目录。也可以支持github的webhook，也能根据不同条件触发不同的webhook，如CI/CD。
环境  CentOS 7 Nginx  ngx_lua lua-resty-shell lua-resty-hmac    配置 对应nginx location配置
location = /webhook/deploy { content_by_lua_file &amp;#39;lua/webhook/deploy.lua&amp;#39;; } deploy.lua
-- Gogs Version: &amp;gt;= v0.10 local require = require local ngx = ngx local cjson = require(&amp;#34;cjson.safe&amp;#34;) local shell = require(&amp;#34;resty.shell&amp;#34;) local hmac = require(&amp;#34;resty.hmac&amp;#34;) local json_encode = cjson.encode local json_decode = cjson.decode -- deploy config local config = { timeout = 30 * 1000, -- 30s socket = &amp;#34;unix:/data/nginx/utils/shell.</description>
    </item>
    
    <item>
      <title>使用Nginx做SNI反向代理</title>
      <link>https://ops.m114.org/post/nginx-sniproxy/</link>
      <pubDate>Wed, 02 Jun 2021 10:18:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/nginx-sniproxy/</guid>
      <description>从 Nginx 1.11.5 版本开始支持用做 SNI 反代，使用 Nginx 做 SNI 反代比用 SNI Proxy 配置起来更简单、更稳定。Nginx stream流程处理见官方文档，此功能可用来加速国外https业务，如苹果订单确认接口。
安装 编译时添加如下参数
 &amp;ndash;with-stream &amp;ndash;with-stream_ssl_preread_module &amp;ndash;with-stream_ssl_module
 配置 基础版
stream { server { listen 443; ssl_preread on; resolver local=on ipv6=off valid=60s; # local=on需要OpenResty补丁 proxy_pass $ssl_preread_server_name:$server_port; } } 优化版
 解决原有无法过滤域名的风险  log_format proxy &amp;#39;$remote_addr [$time_local] $sniproxy_upstream &amp;#39; &amp;#39;$protocol $status $bytes_sent $bytes_received &amp;#39; &amp;#39;$session_time &amp;#34;$upstream_addr&amp;#34; &amp;#39; &amp;#39;&amp;#34;$upstream_bytes_sent&amp;#34; &amp;#34;$upstream_bytes_received&amp;#34; &amp;#34;$upstream_connect_time&amp;#34;&amp;#39;; init_by_lua_block { local sni = require(&amp;#34;resty.sniproxy&amp;#34;) sni.rules = { {&amp;#34;buy.</description>
    </item>
    
    <item>
      <title>Nginx支持WebP</title>
      <link>https://ops.m114.org/post/nginx-support-webp/</link>
      <pubDate>Wed, 02 Jun 2021 10:08:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/nginx-support-webp/</guid>
      <description>WebP格式，Google开发的一种旨在加快图片加载速度的图片格式。图片压缩体积大约只有JPEG的2/3，并能节省大量的服务器带宽资源和数据空间。国外的有 Google（自家的东西肯定要用啦，Chrome Store 甚至已全站使用 WebP）、Facebook 和 ebay，国内的有淘宝、腾讯和美团等。
客户端支持情况:
 Google Chrome 23 起开始支持 WebP（最初发布于2012年11月） Google 的安卓浏览器从 4.2 版本起开始官方支持 WebP（最初发布于2012年11月），4 版本起开始部分支持 Google Chrome安卓版从 Chrome 50 起开始支持 Webp Opera 12.1 开始支持 WebP（最初发布于2012年11月） Edge 18 开始支持 (发布于2018年10月) Firefox 65 支持 (发布于2019年1月)  nginx无缝切换至WebP思路就是：用户访问一张图片(主要为png/jpg格式)，nginx收到请求判断浏览器是否支持WebP，如果支持则返回WebP，不支持则返回原图，达到减少带宽资源的目的。
环境  CentOS 7 libwebp-1.2.0 Nginx  ngx_lua lua-resty-shell    安装部署 cwebp依赖lib
yum -y install libGL libX11 libXi 配置 mime.types新增webp格式支持
image/webp webp; 图片对应nginx location配置
location ~ ^/(images|static)/ { rewrite_by_lua_file &amp;#34;/data/nginx/lua/webp.</description>
    </item>
    
    <item>
      <title>本人OpenResty实践集合</title>
      <link>https://ops.m114.org/post/openresty-case/</link>
      <pubDate>Tue, 01 Jun 2021 10:08:08 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/openresty-case/</guid>
      <description> 优化  支持Brotli Upstream主动健康检查 动态证书 OCSP缓存 ssl分布式session mTLS支持   命令行执行  Nginx支持WebP gogs/gitea webhook   灰度发布  基于IP（动态IP） 自定义变量   微信机器人 安全相关  授权下载 简易CC防护 Gitea通过飞书SSO认证 安全token 防止SNI信息泄露   API服务  IP查询服务 MQ解耦，对接阿里云RocketMQ 对接Kafka 对接Pulsar   缓存服务  主动缓存 SDK缓存   特权进程实践  ipsec操作   代理相关  http代理 SNI代理    </description>
    </item>
    
    <item>
      <title>golang encrypt/decrypt by MacOS keychain</title>
      <link>https://ops.m114.org/post/golang-aes-crypt/</link>
      <pubDate>Tue, 18 May 2021 10:08:00 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/golang-aes-crypt/</guid>
      <description>功能如下:
 AES加密/解密 AES秘钥从MacOS keychain读取 支持Data At Rest Encryption (DARE)，加密文件内存占用小于100K，参考 sio   </description>
    </item>
    
    <item>
      <title>4层TCP转发后获得真实IP之proxy_protocol</title>
      <link>https://ops.m114.org/post/tcp-proxy-get-source-ip-by-proxy_protocol/</link>
      <pubDate>Mon, 19 Apr 2021 17:01:15 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/tcp-proxy-get-source-ip-by-proxy_protocol/</guid>
      <description>需求 后端TCP Server在经过TCP代理(nginx stream模块)后，程序不做任何调整获得用户真实IP。 了解到cloudflare的spectrum产品与我们这个需求一致，刚好有细节和源码分享，参考如下:
 https://blog.cloudflare.com/mmproxy-creative-way-of-preserving-client-ips-in-spectrum/ https://github.com/cloudflare/mmproxy  有公司参考cloudflare的mmproxy，用golang实现了性能更优的版本。
 https://github.com/path-network/go-mmproxy  部署 拓扑与cloudflare spectrum产品一样，示意图如下：
 go &amp;gt; 1.11 as root or with CAP_NET_RAW capability to be able to set IP_TRANSPARENT socket opt.  go get github.com/path-network/go-mmproxy sudo setcap cap_net_raw=+ep $(readlink -f $(which go-mmproxy)) 测试  启动  # go-mmproxy监听端口为25577，TCP后端端口为25578 ip rule add from 127.0.0.1/8 iif lo table 123 ip route add local 0.0.0.0/0 dev lo table 123 go-mmproxy -l 0.</description>
    </item>
    
    <item>
      <title>CentOS8编译安装MySQL 5.7.30</title>
      <link>https://ops.m114.org/post/centos8-build-mysql5.7.30/</link>
      <pubDate>Thu, 18 Jun 2020 13:41:15 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/centos8-build-mysql5.7.30/</guid>
      <description>环境  OS: CentOS 8.2 MySQL: 5.7.30  报错信息 1. 编译报错 CMake Error at plugin/group_replication/libmysqlgcs/rpcgen.cmake:100 (MESSAGE): Could not find rpcgen Call Stack (most recent call first): plugin/group_replication/libmysqlgcs/CMakeLists.txt:38 (INCLUDE) 解决方法
yum --enablerepo=PowerTools install rpcgen 2. systemctl start mysqld.service报错无法启动问题 报错信息如下
[ERROR] Can&amp;#39;t start server: can&amp;#39;t check PID filepath: No such file or directory /usr/lib/systemd/system/mysqld.service 默认配置如下
# Copyright (c) 2015, 2016, Oracle and/or its affiliates. All rights reserved. # # This program is free software; you can redistribute it and/or modify # it under the terms of the GNU General Public License, version 2.</description>
    </item>
    
    <item>
      <title>CentOS7上如何支持安装CentOS8 VM</title>
      <link>https://ops.m114.org/post/centos8-install-on-centos7-kvm/</link>
      <pubDate>Fri, 12 Jun 2020 13:12:06 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/centos8-install-on-centos7-kvm/</guid>
      <description>环境  宿主机：CentOS 7.5 VM: CentOS 8.1  查看支持os osinfo-query os
当前环境默认不支持CentOS8/RHEL8，需做如下操作:
# osinfo-db 需更新至osinfo-db-20190805-2 yum install osinfo-db-tools osinfo-db 报错处理 ERROR &amp;lsquo;virConnect&amp;rsquo; object has no attribute &amp;lsquo;baselineHypervisorCPU&amp;rsquo;
将 libvirt-python-3.9.0-1 升级至 libvirt-python-4.5.0-1 即可解决
参考链接: https://github.com/virt-manager/virt-manager/issues/57</description>
    </item>
    
    <item>
      <title>GitHub supports WebAuthn</title>
      <link>https://ops.m114.org/post/github-supports-webauthn-for-security-keys/</link>
      <pubDate>Fri, 23 Aug 2019 15:05:22 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/github-supports-webauthn-for-security-keys/</guid>
      <description>为了提高 GitHub 帐户的安全性，GitHub平台2019-08-21通过支持 Web 身份验证（WebAuthn）标准宣布了易于使用的身份验证选项。通过 WebAuthn，开发者们现在可以使用物理安全密钥在 GitHub 上进行双因素身份验证。如果你没有物理安全密钥，也可以将笔记本电脑或手机用作安全密钥。
以下是 GitHub 上支持的物理安全密钥的组合：
 Windows，macOS，Linux 和 Android：基于 Firefox 和 Chrome 的浏览器 Windows：Edge macOS：Safari，目前在技术预览版中，但即将推出 iOS：Brave 浏览器以及使用新的 YubiKey 5Ci  你还可以使用以下浏览器和生物识别选项：
 Windows 上的 Microsoft Edge，使用 Windows Hello（带面部识别，指纹识别器或 PIN） 在 macOS 的 Chrome 上使用 Touch ID 在 Android 的 Chrome 上使用指纹识别器  由于平台支持尚未普及，GitHub 目前支持安全密钥作为补充的第二个因素，将来，GitHub 会将安全密钥作为主要的第二因素。
来源：https://github.blog/2019-08-21-github-supports-webauthn-for-security-keys/</description>
    </item>
    
    <item>
      <title>Python的while 1跟while True到底有什么区别?</title>
      <link>https://ops.m114.org/post/python-while-1-vs-for-whiletrue/</link>
      <pubDate>Wed, 23 Jan 2019 17:46:06 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/python-while-1-vs-for-whiletrue/</guid>
      <description>定义两个方法,分别使用while循环
def t1(): while 1: pass def t2(): while True: pass 单从功能上说,两种无任何区别,那么,来看看字节码上的区别:
For Python 2.x
import dis #载入反编译模块,Python内置的 dis.dis(t1) #对应的是while 1,下面是输出 2 0 SETUP_LOOP 3 (to 6) 3 &amp;gt;&amp;gt; 3 JUMP_ABSOLUTE 3 &amp;gt;&amp;gt; 6 LOAD_CONST 0 (None) 9 RETURN_VALUE dis.dis(t2) #对应的是while True,下面是输出 2 0 SETUP_LOOP 10 (to 13) &amp;gt;&amp;gt; 3 LOAD_GLOBAL 0 (True) 6 POP_JUMP_IF_FALSE 12 3 9 JUMP_ABSOLUTE 3 &amp;gt;&amp;gt; 12 POP_BLOCK &amp;gt;&amp;gt; 13 LOAD_CONST 0 (None) 16 RETURN_VALUE 很明显, while 1的字节码只有while True的一半.</description>
    </item>
    
    <item>
      <title>libvirt 4.5 virModuleLoadFile:53</title>
      <link>https://ops.m114.org/post/libvirt-4.5-virModuleLoadFile53/</link>
      <pubDate>Tue, 15 Jan 2019 17:27:22 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/libvirt-4.5-virModuleLoadFile53/</guid>
      <description>CentOS 7.5.1804的libvirt从3.9升级至4.5时，无法启动，报错如下：
 error : virModuleLoadFile:53 : internal error: Failed to load module &amp;lsquo;/usr/lib64/libvirt/storage-backend/libvirt_storage_backend_rbd.so&amp;rsquo;: /usr/lib64/libvirt/storage-backend/libvirt_storage_backend_rbd.so: undefined symbol: rbd_diff_iterate2
 详细报错如下:
[root@localhost ~]# libvirtd -v 2019-01-15 08:56:53.433+0000: 34181: info : libvirt version: 4.5.0, package: 10.el7_6.3 (CentOS BuildSystem &amp;lt;http://bugs.centos.org&amp;gt;, 2018-11-28-20:51:39, x86-01.bsys.centos.org) 2019-01-15 08:56:53.433+0000: 34181: info : hostname: localhost.localdomain 2019-01-15 08:56:53.433+0000: 34181: info : virObjectNew:248 : OBJECT_NEW: obj=0x56166f5da690 classname=virAccessManager 2019-01-15 08:56:53.434+0000: 34181: info : virObjectNew:248 : OBJECT_NEW: obj=0x56166f5cbfe0 classname=virAccessManager 2019-01-15 08:56:53.434+0000: 34181: info : virObjectRef:382 : OBJECT_REF: obj=0x56166f5da690 2019-01-15 08:56:53.</description>
    </item>
    
    <item>
      <title>Python数据库连接池实例--PooledDB</title>
      <link>https://ops.m114.org/post/python-mysql-PooledDB/</link>
      <pubDate>Tue, 16 Oct 2018 16:27:12 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/python-mysql-PooledDB/</guid>
      <description>不用连接池的MySQL连接方法
import MySQLdb conn= MySQLdb.connect(host=&amp;#39;127.0.0.1&amp;#39;,user=&amp;#39;root&amp;#39;,passwd=&amp;#39;password&amp;#39;,db=&amp;#39;DB_test&amp;#39;,port=3306) cur=conn.cursor() SQL=&amp;#34;select * from table_test&amp;#34; cur.execute(SQL) r=cur.fetchall() cur.close() conn.close() 用连接池后的连接方法
import MySQLdb from DBUtils.PooledDB import PooledDB pool = PooledDB(MySQLdb,5,host=&amp;#39;127.0.0.1&amp;#39;,user=&amp;#39;root&amp;#39;,passwd=&amp;#39;password&amp;#39;,db=&amp;#39;DB_test&amp;#39;,port=3306) #5为连接池里的最少连接数 conn = pool.connection() #以后每次需要数据库连接就是用connection()函数获取连接就好了 cur=conn.cursor() SQL=&amp;#34;select * from table_test&amp;#34; cur.execute(SQL) r=cur.fetchall() cur.close() conn.close() PooledDB的参数
 mincached: 最少的空闲连接数，如果空闲连接数小于这个数，pool会创建一个新的连接 maxcached: 最大的空闲连接数，如果空闲连接数大于这个数，pool会关闭空闲连接 maxconnections: 最大的连接数， blocking: 当连接数达到最大的连接数时，在请求连接的时候，如果这个值是True，请求连接的程序会一直等待，直到当前连接数小于最大连接数，如果这个值是False，会报错， maxshared: 当连接数达到这个数，新请求的连接会分享已经分配出去的连接  连接池对性能的提升表现在
 在程序创建连接的时候，可以从一个空闲的连接中获取，不需要重新初始化连接，提升获取连接的速度 关闭连接的时候，把连接放回连接池，而不是真正的关闭，所以可以减少频繁地打开和关闭连接 避免mysql连接数耗尽  DBUtils下载地址：https://pypi.python.org/pypi/DBUtils/</description>
    </item>
    
    <item>
      <title>使用curl请求https时指定IP</title>
      <link>https://ops.m114.org/post/request-https-server-in-custom-ip-with-curl/</link>
      <pubDate>Wed, 06 Jun 2018 10:00:00 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/request-https-server-in-custom-ip-with-curl/</guid>
      <description>一般使用curl请求自定义IP地址并且指定HOST的话可以这样。
curl -H &amp;#39;Host: ops.m114.org&amp;#39; http://127.0.0.1 但是如果你需要请求的地址是HTTPS就不行了
$ curl -H &amp;#39;Host: ops.m114.org&amp;#39; https://127.0.0.1/ curl: (51) Unable to communicate securely with peer: requested domain name does not match the server&amp;#39;s certificate. 因为IP绝大多数情况下无法通过域名证书验证，还好curl中有--resolv参数可以让我们方便的指定域名的解析
# --resolv参数形式 --resolv host:port:address # 示例 curl --resolv ops.m114.org:443:127.0.0.1 https://ops.m114.org Ps:
小编经常使用的CentOS6的自带curl就不支持此参数，幸运的是CentOS7已经支持。</description>
    </item>
    
    <item>
      <title>go如何编译出更小的执行文件?</title>
      <link>https://ops.m114.org/post/go-build-small-exec/</link>
      <pubDate>Wed, 23 Aug 2017 23:38:09 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/go-build-small-exec/</guid>
      <description>前言 本地默认编译出的文件总与官方提供的二进制文件大很多，Google之后得知通过编译参数控制还能编译出更小的可执行文件。
加-ldflags参数 在程序编译的时候可以加上-ldflags &amp;quot;-s -w&amp;quot; 参数来优化编译程序, 其实通过去除部分连接和调试等信息来使得编译之后的执行程序更小,具体参数如下:
 -a 强制编译所有依赖包 -s 去掉符号表信息, panic时候的stack trace就没有任何文件名/行号信息了 -w 去掉DWARF调试信息，得到的程序就不能用gdb调试了  测试代码如下
package main import &amp;#34;fmt&amp;#34; func main() { fmt.Println(&amp;#34;Hello, 世界&amp;#34;) } 编译方式及文件大小对比结果如下
 编译参数   大小     go build(默认)   1.6M    go build -ldflags -s   1.6M    go build -ldflags &amp;#34;-s -w&amp;#34;   1.1M    go build -ldflags -w   1.</description>
    </item>
    
    <item>
      <title>Golang之command line flag笔记</title>
      <link>https://ops.m114.org/post/golang-command-line-flags/</link>
      <pubDate>Wed, 16 Aug 2017 23:28:33 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/golang-command-line-flags/</guid>
      <description>示例代码，仅供参考
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;flag&amp;#34; ) func main() { // golang的flag包的一些基本使用方法  // 待使用的变量  var id int var name string var male bool // 是否已经解析  fmt.Println(&amp;#34;parsed? = &amp;#34;, flag.Parsed()) // 设置flag参数 (变量指针，参数名，默认值，帮助信息)  // 也可以用以下带返回值的方法代替，不过他们返回的是指针，比较麻烦点  // Int(name string, value int, usage string) *int  // String(name string, value string, usage string) *string  // Bool(name string, value bool, usage string) *bool  flag.IntVar(&amp;amp;id, &amp;#34;id&amp;#34;, 123, &amp;#34;help msg for id&amp;#34;) flag.</description>
    </item>
    
    <item>
      <title>analysing java core dump</title>
      <link>https://ops.m114.org/post/analysing-java-core-dump/</link>
      <pubDate>Sun, 23 Jul 2017 16:32:26 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/analysing-java-core-dump/</guid>
      <description>In this post, I will show you how you can debug a Java core file to see what caused your JVM to crash. I will be using a core file I generated in my previous post: Generating a Java Core Dump.
There are different ways you can diagnose a JVM crash, listed below:
The hs_err_pid log file
When a fatal error occurs in the JVM, it produces an error log file called hs_err_pidXXXX.</description>
    </item>
    
    <item>
      <title>Error: 500 OOPS: priv_sock_get_cmd [SOLVED]</title>
      <link>https://ops.m114.org/post/error-500-oops-priv_sock_get_cmd-solved/</link>
      <pubDate>Sun, 23 Jul 2017 16:21:45 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/error-500-oops-priv_sock_get_cmd-solved/</guid>
      <description>Troubleshooting seccomp filter sanboxing with vsftpd 3.0.x
The following error may occur on ftp clients with vsftpd 3.0.x:
500 OOPS: priv_sock_get_cmd This is caused by seccomp filter sanboxing, which is enabled by default on amd64. To workaround this issue, disable seccomp filter sanboxing:
echo &amp;#39;seccomp_sandbox=NO&amp;#39; &amp;gt;&amp;gt; vsftpd.conf service vsftpd restart For further information, refer to Red Hat bug #845980.</description>
    </item>
    
    <item>
      <title>Python版本号比较</title>
      <link>https://ops.m114.org/post/python-version-cmp/</link>
      <pubDate>Sun, 23 Jul 2017 16:13:10 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/python-version-cmp/</guid>
      <description>第一种比较方法(StrictVersion) StrictVersion是由.将一串带有预发布标签的数字分隔为两个或三个部分的格式，预发布标签的字母只能是a或者b加数字版本号，而且只能在最末尾。预发布a版本低于b版本，并且预发布版本永远小于正式发布版本。
合法格式:
0.4 0.4.0 (相同版本) 0.4.1 0.5a1 (预发布版本a1，小于0.5，即0.5版本更新) 0.5b3 0.5 0.9.6 1.0 1.0.4a3 1.0.4b1 1.0.4 非法格式:
1 没有.分隔，需要分隔为2-3部分 2.7.2.2 被分隔成了4个部分 1.3.a4 预发布版本号应该在数字后面 1.3pl1 预发布版本号字母标签只能是a或者b 1.3B1 预发布版本号字母标签只能是a或者b 1.3c 预发布版本号字母标签后必须加数字版本号 版本比较
In [1]: from distutils.version import StrictVersion In [2]: StrictVersion(&amp;#39;1.2a3&amp;#39;) &amp;lt; StrictVersion(&amp;#39;1.2b1&amp;#39;) Out[2]: True In [3]: StrictVersion(&amp;#39;1.2b1&amp;#39;) &amp;lt; StrictVersion(&amp;#39;1.2&amp;#39;) Out[3]: True In [4]: StrictVersion(&amp;#39;1.2&amp;#39;) &amp;lt; StrictVersion(&amp;#39;1.2.1&amp;#39;) Out[4]: True In [5]: StrictVersion(&amp;#39;1.2&amp;#39;) == StrictVersion(&amp;#39;1.2.0&amp;#39;) Out[5]: True In [6]: StrictVersion(&amp;#39;1.2.11&amp;#39;) &amp;lt; StrictVersion(&amp;#39;1.11&amp;#39;) Out[6]: True 第二种比较方法(LooseVersion) LooseVersion格式要求和StrictVersion不同，或者说它并没有任何规定的格式。由一系列数字,相隔时间或字母的字符串组成，并没有一个严格的格式。在进行比较的时候按照数字大小，字符串按字典顺序比较。</description>
    </item>
    
    <item>
      <title>golang sync.WaitGroup解决goroutine同步</title>
      <link>https://ops.m114.org/post/sync-WaitGroup/</link>
      <pubDate>Mon, 03 Jul 2017 16:27:12 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/sync-WaitGroup/</guid>
      <description>**go提供了sync包和channel来解决协程同步和通讯。**新手对channel通道操作起来更容易产生死锁，如果时缓冲的channel还要考虑channel放入和取出数据的速率问题。
从字面就可以理解，sync.WaitGroup是等待一组协程结束。它实现了一个类似任务队列的结构，你可以向队列中加入任务，任务完成后就把任务从队列中移除，如果队列中的任务没有全部完成，队列就会触发阻塞以阻止程序继续运行。
sync.WaitGroup只有3个方法，Add()，Done()，Wait()。 其中Done()是Add(-1)的别名。简单的来说，使用Add()添加计数，Done()减掉一个计数，计数不为0, 阻塞Wait()的运行。
简单示例如下：
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;sync&amp;#34; ) var waitgroup sync.WaitGroup func test(shownum int) { fmt.Println(shownum) waitgroup.Done() //任务完成，将任务队列中的任务数量-1，其实.Done就是.Add(-1) } func main() { for i := 0; i &amp;lt; 10; i++ { waitgroup.Add(1) //每创建一个goroutine，就把任务队列中任务的数量+1 	go test(i) } waitgroup.Wait() //.Wait()这里会发生阻塞，直到队列中所有的任务结束就会解除阻塞 	fmt.Println(&amp;#34;done!&amp;#34;) } Ps: 此文为学习记录，如有错误还请多指教。</description>
    </item>
    
    <item>
      <title>Tomcat 7.0.76 Invalid character found in the request target</title>
      <link>https://ops.m114.org/post/fix-tomcat-upgrade-error/</link>
      <pubDate>Mon, 27 Mar 2017 13:08:25 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/fix-tomcat-upgrade-error/</guid>
      <description>故障现象
升级tomcat至7.0.76后，GET请求的参数中含有中文时tomcat返回400错误，tomcat错误日志如下
java.lang.IllegalArgumentException: Invalid character found in the request target. The valid characters are defined in RFC 7230 and RFC 3986 at org.apache.coyote.http11.InternalNioInputBuffer.parseRequestLine(InternalNioInputBuffer.java:317) at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1000) at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1756) at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1715) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:662) 原因
查询Changelog得知，tomcat 7.0.73版本添加了Add additional checks for valid characters to the HTTP request line parsing so invalid request lines are rejected sooner导致。
解决方法
 请求前自行转义 更换tomcat为较低版本(不过tomcat的这次更改是依据RFC7230 and RFC 3986,在往后的版本,不会移除该特性)  </description>
    </item>
    
    <item>
      <title>不重启解决Too Many Connections</title>
      <link>https://ops.m114.org/post/solve-too-many-connections/</link>
      <pubDate>Sat, 07 Jan 2017 19:57:32 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/solve-too-many-connections/</guid>
      <description>当发生Too many connections时，即使是DBA也无法登录到数据库，一般的做法是修改配置文件的max_connections参数，然后重启数据库，这样业务就有几秒钟的中断，对于线上不能中断的数据库就只能采用另外一种极客的方法了，用gdb直接修改mysqld内存中max_connections的值，具体做法如下：
gdb -p $(cat /data/mysql/mysql-server.pid) -ex &amp;#34;set max_connections=3000&amp;#34; -batch 改进方法如下
通常有两个参数控制控制最大连接数：
max_connections：该实例允许最大的连接数 max_user_connections：该实例允许每个用户的最大连接数 每个人要根据自己业务量，设置合适的值，不要盲目设置过大，但也不可设置过小，因为MySQL在连接数上升的情况下性能下降非常厉害，如果需要大量连接，这时可以引入thread_pool，所以我们需要保持一个原则：系统创建的用户（给应用使用用户）数 * max_user_connections &amp;lt; max_connections。</description>
    </item>
    
    <item>
      <title>在 OpenResty 中使用正则表达式</title>
      <link>https://ops.m114.org/post/use-regular-expressions-in-OpenResty/</link>
      <pubDate>Sun, 30 Oct 2016 10:48:19 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/use-regular-expressions-in-OpenResty/</guid>
      <description>在 OpenResty 中使用正则表达式，社区中推荐的做法是使用ngx.re api。比如匹配一个字符串是否为 http(s) 的链接，可以这么写：
local function is_http_url(s) return ngx.re.find(s, [[^https?://[\w-_?.:/+=&amp;amp;#%]+$]]) end 压测一下:
local t = os.clock() for _ = 1, max do is_http_url(&amp;#34;http://blog.stackoverflow.com/2016/10/Stack-Overflow-92-Podcast-The-Guerilla-Guide-to-Interviewing/?cb=1&amp;#34;) end print(&amp;#34;Time cost: &amp;#34;, os.clock() - t, &amp;#34; s&amp;#34;) 结果：Time cost: 2.663408 s
另一种做法是使用 lua 的正则语法：
local function is_http_url(s) return s:find(&amp;#34;^https?://[%w-_%.%?:/%+=&amp;amp;#%%]+$&amp;#34;) end 结果：Time cost: 0.652221 s
呃，怎么前者耗时是后者的四倍？lua 内置的小小状态机实现，居然打败了大名鼎鼎的 PCRE 库！说好的社区推荐呢！
仔细一瞧，前者的确漏了点东西。ngx.re默认不会缓存正则表达式编译后的结果。一般在其它编程平台上，我们都会先把字符串编译成正则表达式，再用到正则函数中。比如在 Python 里使用 re.compile。所以赶紧补上：
return ngx.re.find(s, [[^https?://[\w-_?.:/+=&amp;amp;#%]+$]], &amp;#34;o&amp;#34;) 好，这次性能有了明显提升：Time cost: 0.646518 s
不错不错，虽然还是跟 lua 的实现不分上下，考虑到 lua 本身的正则支持非常弱（比如连 (foo|bar) 这种形式都不行），而且语法离经叛道，改用 ngx.</description>
    </item>
    
    <item>
      <title>[python]统计列表中重复项的出现次数</title>
      <link>https://ops.m114.org/post/python-count-duplicate-values-of-list/</link>
      <pubDate>Sun, 30 Oct 2016 10:27:24 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/python-count-duplicate-values-of-list/</guid>
      <description>列表项由数字、字符串组成，统计重复项
&amp;gt;&amp;gt;&amp;gt; from collections import defaultdict &amp;gt;&amp;gt;&amp;gt; d = defaultdict(int) &amp;gt;&amp;gt;&amp;gt; for x in [1, 2, 3, 1, 2, 3, 1]: ... d[x] += 1 ... &amp;gt;&amp;gt;&amp;gt; dict(d) {1: 3, 2: 2, 3: 2} &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; c = defaultdict(int) &amp;gt;&amp;gt;&amp;gt; for y in [&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;a&amp;#39;, &amp;#39;c&amp;#39;, &amp;#39;c&amp;#39;]: ... c[y] += 1 ... &amp;gt;&amp;gt;&amp;gt; dict(c) {&amp;#39;a&amp;#39;: 2, &amp;#39;c&amp;#39;: 2, &amp;#39;b&amp;#39;: 1} 列表项由字典组成，统计某一键值的重复数
&amp;gt;&amp;gt;&amp;gt; e = defaultdict(int) &amp;gt;&amp;gt;&amp;gt; for x in [{&amp;#39;a&amp;#39;: 1, &amp;#39;b&amp;#39;: 1}, {&amp;#39;a&amp;#39;: 2, &amp;#39;b&amp;#39;:1}, {&amp;#39;a&amp;#39;: 1, &amp;#39;c&amp;#39;: 3}]: .</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://ops.m114.org/about/</link>
      <pubDate>Sat, 22 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://ops.m114.org/about/</guid>
      <description>收藏站点  OpenResty最佳实践 Jerry Qu HTTPS最佳实践 IP黑名单  Python常用模块  ⭐️requests requests-html records tablib yapf keyring ahocorasick esmre EasyOCR U-2-Net Excel ⭐️httpx ⭐️parsel flashtext pyinotify  Python Web开发  Flask Flask-Orator Sanic  ngx_lua常用模块   OpenResty官方库
 lua-resty-core lua-resty-string lua-resty-mysql lua-resty-redis lua-resty-upload srcache-nginx-module echo-nginx-module set-misc-nginx-module headers-more-nginx-module lua-resty-dns lua-resty-lock lua-resty-limit-traffic lua-upstream-nginx-module lua-resty-upstream-healthcheck lua-resty-balancer lua-resty-shell    APISIX维护库
 apisix lua-resty-http lua-resty-etcd lua-resty-ipmatcher(hash实现) jsonschema lua-resty-prometheus lua-snowflake lua-var-nginx-module    第三方库</description>
    </item>
    
    <item>
      <title>Ceph核心概念备忘录</title>
      <link>https://ops.m114.org/post/ceph-key-concepts-backup/</link>
      <pubDate>Fri, 26 Aug 2016 14:38:12 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/ceph-key-concepts-backup/</guid>
      <description>scrub ceph-osd会定义启动scrub线程，扫描部分对象（哪些对象？），和其他副本比较，发现是否一致。如果发现不一致，ceph会抛出这个异常给用户解决。以PG为粒度，触发scrub。用户手动修复，使用：
ceph pg repair &amp;lt;pg_id&amp;gt; # 全量复制master节点数据到副本节点。 scrub分为light scrubbing和Deep scrubbing，前者是频率多直接检查hash值，后者是频率少直接读取内容计算checksum比较。
backfill 当加入或者减少一个新的osd时，所有remapped之后的PG都要迁移到该osd上，此时就叫做backfill。
recovery 当一个osd或者多个osd崩溃之后，再次上线，该osd的状态已经严重滞后了（此时crushmap中还保持该osd）,这个时候就会进行recovery过程。如果是多个osd recovery, 那么这个时候会占用非常多的服务器资源。
peering 故障恢复时，对比各个副本的PGlog, 根据PGlog差异构造missing列表，恢复阶段根据missing列表来恢复。peering以PG为单位进行，peering过程中，改PG的IO会被挂起，进入recovery阶段，则可以接受IO，但hit到missing列表项的，也会挂起，直到恢复完成后。因为PGlog的记录是有限的，当peering时发现，PGlog差异太大，则会触发backfill。
active + clean PG的status，active的意思是说该PG可以接受读写请求，clean的意思是说PG的副本数达到了要求。
degrade PG的副本数没有达到要求，但是满足最小副本数要求。
incomplete PG的副本数连最小副本数都没有达到。
inconsistent scrub或者deep scrub的时候发现PG内容不一致。
down 关键数据丢失。进入这个状态的一种方法，比如一个PG有两个副本，先down掉其中的一个osd，再down掉第二个osd，最后把第一个osd起起来，这样这个PG就处于down状态。
PGlog和日志文件系统 PGlog相当于undo log, journal相当于redo log。一个是在某个操作执行完成之后，做log记录，如果操作成功，则可以undo；另一个是在某个操作执行之前，做log记录，如果操作失败，下次可以redo。</description>
    </item>
    
    <item>
      <title>ceph pgs inconsistent</title>
      <link>https://ops.m114.org/post/ceph-pgs-inconsistent/</link>
      <pubDate>Wed, 17 Aug 2016 23:44:59 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/ceph-pgs-inconsistent/</guid>
      <description>OSD扩容后出现如下错误
HEALTH_ERR 2 pgs inconsistent; 320 scrub errors
[root@ceph01 ~]# ceph health detail HEALTH_ERR 2 pgs inconsistent; 320 scrub errors pg 10.9 is active+clean+inconsistent, acting [6,0,9] pg 10.10 is active+clean+scrubbing+deep+inconsistent, acting [2,6,4] 320 scrub errors 修复处于不一致状态的pgs
[root@ceph01 ~]# ceph pg repair 10.9 instructing pg 10.9 on osd.6 to repair [root@ceph01 ~]# ceph pg repair 10.10 instructing pg 10.10 on osd.2 to repair 经过一段时间的修复后，ceph恢复正常。</description>
    </item>
    
    <item>
      <title>删除osd的正确方式</title>
      <link>https://ops.m114.org/post/right-steps-delete-ceph-osd/</link>
      <pubDate>Sat, 06 Aug 2016 23:51:26 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/right-steps-delete-ceph-osd/</guid>
      <description>按照官网的步骤走的话，在 标记osd为out 和 从crushmap删除osd 这两步都会触发数据再平衡，如下方式只触发了一次迁移，建议使用。
 调整osd的crush weight   ceph osd crush reweight osd.0 0.1 说明：这个地方如果想慢慢的调整就分几次将crush 的weight 减低到0 ，这个过程实际上是让数据不分布在这个节点上，让数据慢慢的分布到其他节点上，直到最终为没有分布在这个osd，并且迁移完成这个地方不光调整了osd 的crush weight ，实际上同时调整了host 的 weight ，这样会调整集群的整体的crush 分布，在osd 的crush 为0 后， 再对这个osd的任何删除相关操作都不会影响到集群数据的分布。
停止osd进程   systemctl stop ceph-osd@0 这个是通知集群这个osd进程不在了，不提供服务了，因为本身没权重，就不会影响到整体的分布，也就没有迁移
将节点状态标记为out   ceph osd out osd.0 这个是通知集群这个osd不再映射数据了，不提供服务了，因为本身没权重，就不会影响到整体的分布，也就没有迁移
从crush中移除节点   ceph osd crush remove osd.0 这个是从crush中删除，因为已经是0了 所以没影响主机的权重，也就没有迁移了
删除节点   ceph osd rm osd.0 这个是从集群里面删除这个节点的记录
删除节点认证（不删除编号会占住)   ceph auth del osd.</description>
    </item>
    
    <item>
      <title>Centos 7.x systemd对比Centos 6.x daemon</title>
      <link>https://ops.m114.org/post/CentOS7-systemd-vs-CentOS6-daemon/</link>
      <pubDate>Sat, 06 Aug 2016 13:54:53 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/CentOS7-systemd-vs-CentOS6-daemon/</guid>
      <description>从CentOS 7.x开始，CentOS开始使用systemd服务来代替daemon，原来管理系统启动和管理系统服务的相关命令全部由systemctl命令来代替。
1、原来的 service 命令与 systemctl 命令对比    daemon命令 systemctl命令 说明     service [服务] start systemctl start [unit type] 启动服务   service [服务] stop systemctl stop [unit type] 停止服务   service [服务] restart systemctl restart [unit type] 重启服务    此外还有二个systemctl参数没有与service命令参数对应
status: 参数来查看服务运行情况 reload: 重新加载服务，加载更新后的配置文件（并不是所有服务都支持这个参数，比如network.service） 应用举例:
#启动网络服务 systemctl start network.service #停止网络服务 systemctl stop network.service #重启网络服务 systemctl restart network.service #查看网络服务状态 systemctl status network.serivce 2、原来的chkconfig 命令与 systemctl 命令对比 2.</description>
    </item>
    
    <item>
      <title>MySQL Unable to lock ibdata1 error 11 fix</title>
      <link>https://ops.m114.org/post/MySQL-Unable-to-lock-ibdata1-error-11-fix/</link>
      <pubDate>Wed, 03 Aug 2016 10:52:24 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/MySQL-Unable-to-lock-ibdata1-error-11-fix/</guid>
      <description>A bad shutdown can cause such erros on MySQL.
InnoDB: Unable to lock ./ibdata1, error: 11 InnoDB: Check that you do not already have another mysqld process InnoDB: using the same InnoDB data or log files. InnoDB: Error in opening ./ibdata1 For solution mv ibdata1 ibdata1.bak cp -a ibdata1.bak ibdata1 service mysqld restart </description>
    </item>
    
    <item>
      <title>ceph集群jewel版本部署osd激活权限报错</title>
      <link>https://ops.m114.org/post/ceph-jewel-osd-activate-bug/</link>
      <pubDate>Fri, 29 Jul 2016 00:29:29 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/ceph-jewel-osd-activate-bug/</guid>
      <description>环境
ceph version 10.2.2 (45107e21c568dd033c2f0a3107dec8f0b0e58374)ceph-deploy 1.5.34
ceph集群jewel版本部署过程中执行osd激活操作如下
ceph-deploy osd activate ceph13:/dev/sdb1:/dev/sda2 报错内容如下
[2016-07-29 00:05:19,106][ceph_deploy.conf][DEBUG ] found configuration file at: /root/.cephdeploy.conf [2016-07-29 00:05:19,107][ceph_deploy.cli][INFO ] Invoked (1.5.34): /bin/ceph-deploy osd activate ceph13:/dev/sdb1:/dev/sda2 [2016-07-29 00:05:19,107][ceph_deploy.cli][INFO ] ceph-deploy options: [2016-07-29 00:05:19,108][ceph_deploy.cli][INFO ] username : None [2016-07-29 00:05:19,108][ceph_deploy.cli][INFO ] verbose : False [2016-07-29 00:05:19,108][ceph_deploy.cli][INFO ] overwrite_conf : False [2016-07-29 00:05:19,108][ceph_deploy.cli][INFO ] subcommand : activate [2016-07-29 00:05:19,108][ceph_deploy.cli][INFO ] quiet : False [2016-07-29 00:05:19,108][ceph_deploy.cli][INFO ] cd_conf : &amp;lt;ceph_deploy.conf.cephdeploy.Conf instance at 0x26dcb90&amp;gt; [2016-07-29 00:05:19,109][ceph_deploy.</description>
    </item>
    
    <item>
      <title>使用国内源部署Ceph</title>
      <link>https://ops.m114.org/post/deploy-ceph-using-china-mirror/</link>
      <pubDate>Thu, 28 Jul 2016 13:17:52 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/deploy-ceph-using-china-mirror/</guid>
      <description>由于网络方面的原因，Ceph的部署经常受到干扰，通常为了加速部署，基本上大家都是将Ceph的源同步到本地进行安装。根据Ceph中国社区的统计，当前已经有国内的网站定期将Ceph安装源同步，极大的方便了我们的测试。本文就是介绍如何使用国内源，加速ceph-deploy部署Ceph集群。
关于国内源 根据Ceph中国社区的统计，国内已经有四家网站开始同步Ceph源，分别是：
 网易镜像源http://mirrors.163.com/ceph 阿里镜像源http://mirrors.aliyun.com/ceph 中科大镜像源http://mirrors.ustc.edu.cn/ceph 宝德镜像源http://mirrors.plcloud.com/ceph  安装Ceph(Jewel版) 由于Jewel版本中已经不提供el6的镜像源，所以只能使用CentOS 7以上版本进行安装。我们并不需要在repos里增加相应的源，只需要设置环境变量，即可让ceph-deploy使用国内源，具体过程如下：
export CEPH_DEPLOY_REPO_URL=http://mirrors.aliyun.com/ceph/rpm-jewel/el7 export CEPH_DEPLOY_GPG_URL=http://mirrors.aliyun.com/ceph/keys/release.asc 之后的过程就没任何区别了
# Create monitor node ceph-deploy new node1 node2 node3 # Software Installation ceph-deploy install deploy node1 node2 node3 # Gather keys ceph-deploy mon create-initial # Ceph deploy osd create disk ceph-deploy osd create node1:sdb:/dev/sdc ceph-deploy osd create node2:sdb:/dev/sdc ceph-deploy osd create node3:sdb:/dev/sdc # Make 3 copies by default echo &amp;#34;osd pool default size = 3&amp;#34; | tee -a $HOME/ceph.</description>
    </item>
    
    <item>
      <title>R420服务器idrac连接用户数超限制</title>
      <link>https://ops.m114.org/post/fix-dell-idrac-7-error-rac0218-the-maximum-number-of-user-sessions-is-reached/</link>
      <pubDate>Tue, 12 Jul 2016 23:29:35 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/fix-dell-idrac-7-error-rac0218-the-maximum-number-of-user-sessions-is-reached/</guid>
      <description>Dell R420服务器中，比较经常出现idrac无法连接，或者连接用户数超限(RAC0218错误)的问题，升级iDrac卡firmware至1.57.57即可解决。
该版本的bug fix中提到过一点：
 Fix for issues that cause iDRAC7 sluggish responsiveness after a prolonged period of time (approx. 45-100 days, depending on the usage). In some cases, if the iDRAC is not reset, the iDRAC may become unresponsive and requires a server AC Power on reset. This issue was introduced in firmware release 1.50.50 and fixed in 1.56.55.  RAC0218: The maximum number of user sessions is reached. 2种临时解决方法(idrac重新初始化)</description>
    </item>
    
    <item>
      <title>运维工具汇总之 性能调优，性能监控，性能测试</title>
      <link>https://ops.m114.org/post/linux-performance-tools/</link>
      <pubDate>Sun, 03 Jul 2016 13:39:01 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/linux-performance-tools/</guid>
      <description>性能调优 性能监控 性能测试 </description>
    </item>
    
    <item>
      <title>Git常用命令备忘</title>
      <link>https://ops.m114.org/post/git-common-command/</link>
      <pubDate>Thu, 16 Jun 2016 12:33:10 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/git-common-command/</guid>
      <description>配置 Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。
# 显示当前的Git配置 $ git config --list # 文本编辑器 $ git config --global core.editor vim # 编辑Git配置文件 $ git config -e [--global] # 设置提交代码时的用户信息 $ git config [--global] user.name &amp;#34;[name]&amp;#34; $ git config [--global] user.email &amp;#34;[email address]&amp;#34; FAQ 1. 如果在你Fork之后，原始的repo更新了，怎么将原始的更新内容与你当前的合并？ 1. 增加原分支为远程分支，命名为upstream git remote add upstream https://github.com/vinsonzou/docker-images.git 2. fetch该远程仓库下的所有分支到remote-tracking分支 git fetch upstream 3. 确保你当前在master分支 git checkout master 4. Fork同步 两种方式，任选其一即可 a) 如果你已经对当前自己的副本做过更改，并且想要保留，则将更新合并到主分支 git merge upstream/master b) 如果想要保留所有原仓库的历史更新则使用rebase复写当前分支(`本地所有修改丢失`) git rebase upstream/master 5.</description>
    </item>
    
    <item>
      <title>Docker for Mac Beta尝鲜</title>
      <link>https://ops.m114.org/post/docker-for-mac-beta/</link>
      <pubDate>Fri, 20 May 2016 00:05:35 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/docker-for-mac-beta/</guid>
      <description>Docker for Mac Docker for Mac 是一个原生的苹果应用程序，被安装到 /Application 目录。安装时会创建 /usr/local/bin 目录下的 docker、docker-compose、docker-machine 符号链接，这些符号链接指向 ~/Library/Group Containers/group.com.docker/bin 目录下的各类文件，而 ~/Library/Group Containers/group.com.docker/bin 的文件实际上也是符号链接，他们指向 /Applications/Docker.app/Contents/Resources/bin 目录下的实际二进制文件。
 Docker for Mac 使用通过 Hypervisor.framework 提供的轻量级的 xhyve 虚拟化技术 Docker for Mac 不使用 docker-machine 管理虚拟机 Docker for Mac 不通过 TCP 端口通信，反而使用 /var/tmp/docker.sock 套接字文件通信（实际上是将 /var/tmp 目录挂载到了虚拟机中，虚拟机在其中生成套接字文件） 由于使用了 xhyve 虚拟机，所以可以模拟不同架构的处理器，这样开发者就直接能在 Mac 上使用 Docker 使用诸多平台的镜像文件，比如 arm 等。  为了能主机虚拟机共享文件，Docker 使用 osxfs 作为全新的文件共享方案，在很多方面都有全新的特性，比如在文件权限、命名空间、文件所有者、文件系统事件、挂载点、符号链接、文件类型、扩展属性等方面都有了全新的内容，并且，所有产生的日志都能通过 syslog 查询，非常方便。不过现在依旧存在许多问题，比如没有设置 docker daemon 各项参数的接口。
如何为Docker Engine设置代理 screen ~/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/tty 敲一下回车，登录，用户名root，没有密码，直接回车。编辑/etc/init.d/docker文件，如下添加代理：</description>
    </item>
    
    <item>
      <title>kernel igb 00000500 0 eth0 reset adapter</title>
      <link>https://ops.m114.org/post/kernel-igb-00000100-0-eth0-reset-adapter/</link>
      <pubDate>Wed, 03 Jun 2015 23:04:55 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/kernel-igb-00000100-0-eth0-reset-adapter/</guid>
      <description>系统环境
 CentOS 6.4 igb driver version 4.0.1-k  报错信息如下
Jun 3 13:20:05 localhost kernel: igb 0000:05:00.1: eth1: Reset adapter Jun 3 13:20:06 localhost kernel: igb 0000:05:00.0: eth0: Reset adapter Jun 3 13:20:11 localhost kernel: igb: eth1 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX Jun 3 13:20:12 localhost kernel: igb: eth0 NIC Link is Up 1000 Mbps Full Duplex, Flow Control: RX Jun 3 13:55:26 localhost kernel: igb 0000:05:00.</description>
    </item>
    
    <item>
      <title>DNSPOD API SSL证书调整(subjectAltName)引起的报错</title>
      <link>https://ops.m114.org/post/DNSPOD-API-SSL-subjectAltName/</link>
      <pubDate>Sun, 10 May 2015 23:44:43 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/DNSPOD-API-SSL-subjectAltName/</guid>
      <description>报错信息如下：
Python 2.7 (r27:82500, Jan 7 2014, 23:14:35) [GCC 4.1.2 20080704 (Red Hat 4.1.2-50)] on linux2 Type &amp;#34;help&amp;#34;, &amp;#34;copyright&amp;#34;, &amp;#34;credits&amp;#34; or &amp;#34;license&amp;#34; for more information. &amp;gt;&amp;gt;&amp;gt; import requests &amp;gt;&amp;gt;&amp;gt; r = requests.get(&amp;#34;https://dnsapi.cn&amp;#34;) Traceback (most recent call last): File &amp;#34;&amp;lt;stdin&amp;gt;&amp;#34;, line 1, in &amp;lt;module&amp;gt; File &amp;#34;/usr/local/lib/python2.7/site-packages/requests-2.0.0-py2.7.egg/requests/api.py&amp;#34;, line 55, in get return request(&amp;#39;get&amp;#39;, url, **kwargs) File &amp;#34;/usr/local/lib/python2.7/site-packages/requests-2.0.0-py2.7.egg/requests/api.py&amp;#34;, line 44, in request return session.request(method=method, url=url, **kwargs) File &amp;#34;/usr/local/lib/python2.7/site-packages/requests-2.0.0-py2.7.egg/requests/sessions.py&amp;#34;, line 361, in request resp = self.</description>
    </item>
    
    <item>
      <title>俄罗斯永久冬令时的坑</title>
      <link>https://ops.m114.org/post/russia-permanent-winter-time/</link>
      <pubDate>Sun, 26 Apr 2015 16:59:30 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/russia-permanent-winter-time/</guid>
      <description>本文更新说明  2017.03.17: 修复java时区更新方法  系统环境 OS: CentOS 6.X
JDK: 6
背景 因游戏在俄罗斯运营，采用了莫斯科时间，俄罗斯宣布2014年10月26日开始永久冬令时。
过程 更新了系统时区文件，保证系统时间不会切换至夏令时，执行yum update tzdata即可。
但在莫斯科时间的2015年3月29日凌晨2点，java游戏进程的日志时间跳到了凌晨3点(比系统时间快了1个小时)
解决方法 使用Oracle TZUpdater进行更新即可
java -jar tzupdater.jar -l http://www.iana.org/time-zones/repository/tzdata-latest.tar.gz 工具地址：http://www.oracle.com/technetwork/java/javase/downloads/tzupdater-download-513681.html
参考：http://www.jvmhost.com/articles/java-and-timezones/</description>
    </item>
    
    <item>
      <title>利用TsunamiUDP加速跨机房迁移</title>
      <link>https://ops.m114.org/post/Use-TsunamiUDP-accelerate-migration-across-data-centers/</link>
      <pubDate>Sun, 26 Apr 2015 16:00:00 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/Use-TsunamiUDP-accelerate-migration-across-data-centers/</guid>
      <description>部署 yum -y install automake autoconf git clone git://github.com/rriley/tsunami-udp.git cd tsunami-udp ./recompile.sh cp server/tsunamid client/tsunami /usr/bin #或者从sf.net下载 wget http://iweb.dl.sourceforge.net/project/tsunami-udp/tsunami-udp/tsunami-v1.1-cvsbuild42/tsunami-v1.1-cvsbuild42.tar.gz tar zxf tsunami-v1.1-cvsbuild42.tar.gz cd tsunami-udp-v11-b42 ./recompile.sh cp server/tsunamid client/tsunami /usr/bin 使用 #1、防火墙调整 #服务端：开启TCP 46224(默认端口) #客户端：开启UDP 46224(默认端口) #2、开启服务端 #待迁移文件都放在/app/game_data目录下(也可指定单文件传输) tsunamid --hbtimeout 60 /app/game_data/* #PS：这里设定心跳包超时时间为60秒，默认为15秒，在使用中很容易中断导致传输失败 #3、开启客户端 # 拉取服务端(122.225.100.100)的game_db.lz4文件，并限速100M(建议限制下，不然机房带宽就满了哦) tsunami set rate 100M connect 122.225.100.100 get gcmob_db.lz4 # 拉取目录下所有文件 tsunami set rate 100M connect 122.225.100.100 get \* #文档：http://tsunami-udp.cvs.sourceforge.net/viewvc/tsunami-udp/docs/USAGE.txt PS：未避免泄密，IP是随机填的 跨机房迁移示例 场景： 将14G文件从杭州机房迁移至北京机房
  方法1：使用wget下载   方法2：使用TsunamiUDP工具   总结:</description>
    </item>
    
    <item>
      <title>Zabbix使用Telegram发送报警</title>
      <link>https://ops.m114.org/post/zabbix-alerts-use-telegram/</link>
      <pubDate>Sat, 25 Apr 2015 17:16:29 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/zabbix-alerts-use-telegram/</guid>
      <description>环境 CentOS 6.X x86_64
编译Telegram yum -y install lua-devel openssl-devel libconfig-devel readline-devel libevent-devel git clone --recursive https://github.com/vysheng/tg.git cd tg ./configure make mkdir /usr/local/tg cp tg-server.pub /usr/local/tg cp bin/telegram-cli /usr/local/tg zabbix报警脚本/usr/local/tg/telegram.sh:
#!/bin/sh  cd `dirname $0` ./telegram-cli -k tg-server.pub -WDCRE -P 8890 -d &amp;amp;&amp;gt;/dev/null &amp;amp; Zabbix报警配置 将如下Zabbix Server配置注释并修改如下 AlertScriptsPath=/usr/local/zabbix/alertscripts
/usr/local/zabbix/alertscripts/tg.sh内容如下:
#!/bin/sh  export to=$1; export subject=$2; export body=$3; echo -e &amp;#34;msg $to${subject}_#_${body}&amp;#34; | nc localhost 8890 #注意事项: body只能有一行内容，超过一行的内容是不会发送的。 Zabbix添加Media types PS：Telegram已于2015年7月10日被天朝和谐。。。</description>
    </item>
    
    <item>
      <title>Monitor SSL certificate expiry</title>
      <link>https://ops.m114.org/post/monitor-ssl-certificate-expiry/</link>
      <pubDate>Sat, 25 Apr 2015 16:31:41 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/monitor-ssl-certificate-expiry/</guid>
      <description>看到网上弄了个zabbix监控SSL证书过期时间的,给咱业务也加了个此监控。
改进如下：
  基于域名监控(一台服务器上有多个证书)   当前使用的shell脚本如下
#!/bin/sh  host=$1 port=443 end_date=`openssl s_client -servername $host -host $host -port $port -showcerts &amp;lt;/dev/null 2&amp;gt;/dev/null | sed -n &amp;#39;/BEGIN CERTIFICATE/,/END CERT/p&amp;#39; | openssl x509 -text 2&amp;gt;/dev/null | sed -n &amp;#39;s/ *Not After : *//p&amp;#39;` # openssl 检验和验证SSL证书。 # -servername $host 因一台主机存在多个证书，利用SNI特性检查 # &amp;lt;/dev/null 定向标准输入，防止交互式程序Hang。从/dev/null 读时，直接读出0 。 # sed -n 和p 一起使用，仅显示匹配到的部分。 //,// 区间匹配。 # openssl x509 -text 解码证书信息，包含证书的有效期。 if [ -n &amp;#34;$end_date&amp;#34; ] then end_date_seconds=`date &amp;#39;+%s&amp;#39; --date &amp;#34;$end_date&amp;#34;` now_seconds=`date &amp;#39;+%s&amp;#39;` echo &amp;#34;($end_date_seconds-$now_seconds)/24/3600&amp;#34; | bc fi </description>
    </item>
    
    <item>
      <title>使用Hugo搭建免费个人Blog</title>
      <link>https://ops.m114.org/post/how-to-use-hugo/</link>
      <pubDate>Tue, 11 Nov 2014 17:15:00 +0800</pubDate>
      
      <guid>https://ops.m114.org/post/how-to-use-hugo/</guid>
      <description>Hugo是什么 Hugo是一个工具，可以用于搭建静态站点，类似jekyll，不过Hugo是Golang写的，大家应该知道Golang有一个对部署友好的特点，那就是静态编译，所以安装起来非常方便，不像jekyll安装起来比较麻烦。
可能有些读者也不知道jekyll是干啥的，我这简单解释一下，这些软件通常可以叫做静态站点生成器，我们可以使用Markdown格式编写一些文本，按照指定的目录结构存放，然后再在指定的目录里放置css等静态文件，jekyll就可以帮你生成一个静态站点。那既然是静态站点，你就可以很方便的部署了，因为只要搭配一个web server即可，甚至可以部署在github pages上，ops.m114.org是部署在gitcafe pages上的，这样国人访问速度快一些。因为github和gitcafe的pages功能是免费的，这也是我标题中“免费”二次的原因
Hugo的使用 Hugo的官网是gohugo.io，里边有个Docs，大家可以跟着走一遍，主要是里边的quickstart。笔者就不给大家做翻译了，给读者介绍一下如何基于笔者这个Blog来搭建，在这基础上修改就要容易不少了。
下载Hugo 官网上首页就有下载链接，去Hugo下载即可
把笔者的这个blog clone下来 git clone https://github.com/vinsonzou/hugo.blog.git cd hugo.blog hugo server -w  上面的代码是Linux、OS X控制台命令，windows用户请自己转换成windows操作方法。看到控制台打印出的内容了么？Hugo已经帮忙生成了一个静态站点，并且监听在本机的1313端口，访问一下试试吧：）
修改hugo.blog 一行代码就跑起来了，是不是so easy，接下来笔者大体介绍一下各个目录中的作用，读者可以修改成自己的一些信息
content目录就是存放你原始markdown文本的地方，content的子目录和markdown文件名组成了url地址，比如这篇文章的url是：http://ops.m114.org/post/how-to-use-hugo/ ，那是因为content目录下有个post/how-to-use-hugo.md
public目录是刚才运行hugo server -w命令生成的，这里边的内容就是静态站点的内容，之后咱们把这些内容提交到gitcafe pages中
static目录是存放一些静态资源
themes目录是主题目录，我使用了hyde这个主题，在上面做了一些修改，读者要想让Blog比较个性化，就可以定制主题
themes/hyde/{layouts,static}是我们主要修改的内容。index.html是首页，你修改一下看看，浏览器会自动刷新看到效果；partials目录是存放的一些页面片段，便于复用；_default目录是博文单页和博文列表页面，相信你一看就懂；static目录中有一些css，想怎么个性化就调整它们就成了
使用gitcafe pages制作站点 上面搞定之后，最好把修改之后的内容push到github上。public目录无需push，这是每次都可以自动生成的。咱们这里要把public也作为一个repo，push到gitcafe，生成静态站点。
gitcafe有个帮助文档：GitCafe Pages，照着搞一下，把public的内容push上去，绑定域名，O了
是不是很简单，有明白的地方可以查看Hugo文档或留言。</description>
    </item>
    
  </channel>
</rss>
